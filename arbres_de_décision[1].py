# -*- coding: utf-8 -*-
"""Arbres de décision.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1rY4oiCGPIFGYwsyruH9mVrasVq6dhF2q
"""

# importation des données
# code provenant du notebook jupyter sur l'ENT MLR
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import math
from sklearn import neighbors
from sklearn.model_selection import train_test_split, cross_val_score, cross_validate
from sklearn.model_selection import ShuffleSplit, GridSearchCV

from sklearn.tree import DecisionTreeClassifier, plot_tree
from scipy.stats import stats
from sklearn.model_selection import cross_validate
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay

n = 31405
p = 0.3
Skiprows = np.where(np.random.uniform(size=(n)) > p)[0]

varnames = [str(i) for i in range(2497)]
data1 = pd.read_csv("https://perso.univ-rennes1.fr/valerie.monbet/MachineLearning/AndroidMalware_Training_set.csv",
                  sep=",",skiprows=Skiprows,
                  names = varnames,
                  header=None)

# on retire l'ensemble des échantillons sur laquelle on va faire nos tests et appliquer l'algorithme
# on retire le hash les deux colonnes suivants, non nécessaires pour l'apprentissage après
data2 = data1.drop(data1.columns[[2493, 2494, 2496]], axis=1)

# extractions des données
X = data2.iloc[:, :2492]
Y = data2.iloc[:, -1]

# Triage des données. On retire les NaN
X = X.dropna()
Y = Y.dropna()

# on sépare les données en deux ensembles - une pour l'apprentissage et l'autre pour le test
X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state=42)

scaler = StandardScaler()
X_train_sc = scaler.fit_transform(X_train)
X = scaler.transform(X)

# on met en place un arbre pour prédire le type de spam
arbre = DecisionTreeClassifier()

#les paramètres à tester
paramgrid = {'max_depth':[2, 4, 6, 8, 10], 'min_samples_leaf':[5, 10, 15, 20]}

# on simule les différents forets et choisi le meilleur
recherche_arbre = GridSearchCV(estimator=arbre, param_grid = paramgrid, scoring='f1_weighted', cv=5, n_jobs = -1)
recherche_arbre.fit(X_train, y_train)

print(recherche_arbre.best_estimator_)

# on affiche l'éfficacité de prédiction (f1 weighted score)  pour le max_depth 10 et le min samples leaf allant de 5 à 20
samples_leaf = [5, 10, 15, 20]
erreur_f1 = [0, 0, 0, 0]

for h in range(4):

    sample_arbre = DecisionTreeClassifier(max_depth=10, min_samples_leaf=samples_leaf[h])
    sample_arbre.fit(X_train, y_train)
    
    # on calcule l'erreur
    cv_scores = cross_validate(sample_arbre, X, Y, cv=5, n_jobs = -1, scoring='f1_weighted')
    erreur_f1[h] = np.round(np.mean(cv_scores['test_score']),3)

print(erreur_f1)

plt.plot(samples_leaf, erreur_f1, 'r')
plt.legend(['F1 Weighted'])
plt.xlabel("Nombre minimal d'éléments dans une feuille")
plt.ylabel('Scoring F1 Weighted')
plt.show()

# On calcule le meilleur arbre
meilleur_arbre = DecisionTreeClassifier(max_depth=10, min_samples_leaf=5)
meilleur_arbre.fit(X_train_sc, y_train) # appretissage

# on affiche les erreurs de classfication utilisant la matrice de confusion
arbre_predit = meilleur_arbre.predict(X_test)

# comparaison des classifications et afichage d'une matrice de confusion
nos_labels = Y.unique()
matrice_de_confusion = confusion_matrix(arbre_predit, y_test, normalize="true", labels = nos_labels)
conf_disp = ConfusionMatrixDisplay(matrice_de_confusion, display_labels=nos_labels)

fig, ax = plt.subplots(figsize=(12,12))
conf_disp.plot(ax=ax)
plt.show()