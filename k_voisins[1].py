# -*- coding: utf-8 -*-
"""K_voisins.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dCHz5Ho0HkZuV4x_M2AG0s_xAGwUSDqA
"""

# importation des données
# code provenant du notebook jupyter sur l'ENT MLR
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import math
from sklearn import neighbors
from sklearn.model_selection import train_test_split, cross_val_score, cross_validate
from sklearn.model_selection import ShuffleSplit, GridSearchCV

import scipy.stats as stats
from sklearn.model_selection import cross_validate
from sklearn.neighbors import KNeighborsClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay

n = 31405
p = 0.3
Skiprows = np.where(np.random.uniform(size=(n)) > p)[0]

varnames = [str(i) for i in range(2497)]
data1 = pd.read_csv("https://perso.univ-rennes1.fr/valerie.monbet/MachineLearning/AndroidMalware_Training_set.csv",
                  sep=",",skiprows=Skiprows,
                  names = varnames,
                  header=None)

# on retire l'ensemble des échantillons sur laquelle on va faire nos tests et appliquer l'algorithme
# on retire le hash les deux colonnes suivants, non nécessaires pour l'apprentissage après
data2 = data1.drop(data1.columns[[2493, 2494, 2496]], axis=1)

# extractions des données
X = data2.iloc[:, :2492]
Y = data2.iloc[:, -1]

# Triage des données. On retire les NaN
X = X.dropna()
Y = Y.dropna()

# on sépare les données en deux ensembles - une pour l'apprentissage et l'autre pour le test
X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state=42)

scaler = StandardScaler()
X_train_sc = scaler.fit_transform(X_train)
X = scaler.transform(X)

# on teste avec le méthode des plus proches voisins afin de comparer la différence
# on recherche le meilleur nombre de voisins
knn = KNeighborsClassifier(weights="distance", metric="manhattan")
param_grid = [{'n_neighbors': [20, 40, 60, 80, 100]}]

search = GridSearchCV(knn, param_grid, scoring="f1_weighted",cv=5,n_jobs=-1)

search.fit(X_train_sc,y_train)
print(search.best_estimator_)

# on cherche et affiche l'erreur du meilleur classifieurs
meilleur_estimateur_voisins = KNeighborsClassifier(n_neighbors= 20, weights="distance", metric="manhattan")
meilleur_estimateur_voisins.fit(X_train_sc, y_train)

score_validation = cross_validate(meilleur_estimateur_voisins, X, Y, cv= 5, scoring="f1_weighted")
print(score_validation)
print(np.mean(score_validation["test_score"]))

# On définie des fonctions pour les noyaux d'estimations
# fonction de poids pour un noyau tri_cube
def tri_cube(x, y, h):
    if math.dist(x, y) < (h ** 2):
        weight = ((1 - (math.sqrt(math.dist(x,y))) ** 3) ** 3)
    else:
        weight = 0

    return 1/weight


# fonction pour définir poids pour un noyau gausienne
def gausienne(x, y, h):
    weight = stats.norm.pdf(math.sqrt(math.dist(y,x)),loc=math.sqrt(math.dist(x, x)), scale=h)

    return 1/weight


# fonction pour définir poids pour un noyau gausienne
def uniforme(x, y, h):
    if math.dist(x, y) < ((h / 2) ** 2):
        return h # puisque le noyau est l'inverse du distance
    else:
        return 0

# on recherche le rayon optimale pour l'estimation
# le nombre de voisins est 100 par défaut

# on utilise la méthode Bootstrap bagging pour ameliorer le temps de calcul
# on extrait des sous-échantillons à chaque fois et on calcule une moyenne

for h in [20, 40, 60, 80, 100]:
    score = 0

    for i in range(10):
      # on extrait une dixième des données pour faire de l'appretissage
      n_apprentissage= len(Y) // 10
      per=np.random.permutation(len(Y)) # tirage aléatoire des données

      indice_apprentissage=per[:n_apprentissage]
      X_apprentissage= X[indice_apprentissage,:]
      Y_apprentissage= Y[indice_apprentissage]

      ppv = KNeighborsClassifier(n_neighbors=100, weights='distance', metric=lambda a,b: tri_cube(a,b, h))
      ppv.fit(X_apprentissage, Y_apprentissage)

      # on extrait une autre dixième pour faire la validation croisée
      n_test= len(Y) // 10
      per=np.random.permutation(len(Y)) # tirage aléatoire des données

      indice_test=per[:n_test]
      X_test_br= X[indice_test,:]
      Y_test_br= Y[indice_test]

      # calculation de l'erreur
      score_validation = cross_validate(ppv, X_test_br, Y_test_br, cv=5, scoring="f1_weighted")
      score += np.mean(score_validation["test_score"])

    print(h)
    print(score/10) # moyenne de l'érreur

# on teste avec le méthode des plus proches voisins afin de comparer la différence
# on recherche le meilleur nombre de voisins
knn = KNeighborsClassifier(weights="distance", metric="manhattan")

for h in [20, 40, 60, 80, 100]:
    ppv = KNeighborsClassifier(n_neighbors=h, weights="distance", metric="manhattan")
    ppv.fit(X_train_sc, y_train)

    score_validation = cross_validate(ppv, X_test, y_test, cv=5, scoring="f1_weighted")
    print(np.mean(score_validation["test_score"]))